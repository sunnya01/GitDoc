## IO流&字符集编解码

#### IO流

###### File 文件对象流处理的根对象，主要涉及到绝对路径和相对路径，根据路径实例化，可以通过实例化对象获取文件信息，或者操作文件但无法操作文件里面的字节

###### 类似在终端输入指令的效果

###### Reader Writer(字符流按照2字节读取，jdk8及以前解码过程与系统设置的默认解码格式有关但是解码以后得到的码点在jvm中都按照utf-16编码存储在char数组中) InputStream OutputStream(字节流按照单字节读取) 节点流，在文件根之上的底层流，直接连接jvm和文件字节码

###### 由于字符流读取编码解码与系统设置绑定操作性较差，因此引入转换流InputStreamReader 读取的时候按照单字节读入可以在构造方法中填入编码方式并可以直接返回字符 OutputStreamWriter 可以在构造方法中写入编码方式，并直接给入指定的字符数组，按照编码方式编码后通过单字节写入目标节点文件

###### 这两个流称为处理流，必须依赖于节点流

###### BufferInputStream、BufferOutputStream、BufferReader 、 BufferWriter缓冲流，用来提高性能的处理流，和其他处理流并非多选一的关系，而是可以再嵌套的关系例如 File对象->FileInputStream节点流对象 -> BufferInputStream缓冲流处理流包装 -> InputStreamReader转换流处理流包装

#### 字节转换

1. 数值类型的转换比特位总结: 以java中的byte为例,byte是一个字节即8bit的整型数据,可表示范围为-128～127(解析---首先第一位表示符号位0表示这个字节表示正数,1表示这个字节表示负数。当第一位为0时,剩余7为可以表达的数值范围是0～127(0000 0000 ~ 0111 1111)所以正数的最大值是127||当第一位为1时,数值位负数,负数的值表示剩余8位字节的反码+1,即表示的范围为 1000 0000 ～ 1111 1111,再由于取得是反码+1,因此负数的最小值-128是1000 0000中的后7位000 000的反码111 1111即127 + 1 = 128,负数的最大值是1111 1111的后7位的反码111 1111的反码000 0000 + 1 = 1)总结 字节类型转换为整数时,正数是符号位去掉以后剩下位数的二进制转换为10进制的值，负数是去掉符号位以后剩下位数的二进制取反码后加1得到的值
2. 字符串编码以及java中的char单字符类型总结: 只以Unicode举例，因为他兼容了所有以往的编码集(与编码方式的概念不同，编码方式表示的一个字符的内容与底层二进制转换的一套关系，转换完成以后的二进制的一定可以按照某种算法得到一个码点，但是不一定就是这个码点。而编码集表示的是固定的字符与码点的关系，也就是一个字符可以在编码集里面找到一个固定的码点例如英文a在Unicode编码集合中的码点是97即二进制的01100001,但是他在内存中保存的时候不一定是这样的因为具体保存是要关联上编码的方式，如果这里是按照UTF-16保存这个编码,根据该编码方式在基本面的码点都用两个字节保存在内存中就会体现为0000 0000 0110 0001), 接下来具体介绍一下Unicode和UTF-8 UTF-16 UTF-32，
3. Unicode目前用的最全的字符集: 它使用了三个字节作为码点表示与字符的映射关系,但是具体只使用了(16进制表示)0x000000~10FFFF的内容,经过简单计算可以知道这个字符集最多可以包含1114111个码点,理论上可以涵盖所有的人类字符文本,但是实际这个字符集在程序使用中无法直接按照码点的值保存,因为这里涉及到内存空间的问题,虽然所有的码点都可以用3个字节涵盖,但是对于大部分常用字符例如兼容进来的asc码表上的就会出现占用2个空白字节的问题,这种空白占用不仅浪费了内存空间，还导致计算的过程需要考虑空白字节从而影响计算的效率(但是这里要说明不是字节少就代表效率高,以UTF-8为例虽然他对asc码表内的单字节内容始终表示为相同码点保存在内存空间中,但是它的编码方式是变长的如果包含了其他字节例如中文则会变成3个字节，因此在计算时需要额外考虑字节的前后关系以及组合字节计算才能得到正确的值这样会导致计算时同样会低效率并且出错时排查困难或者数据丢失导致的乱码影响会放大),因此Uncode同时推出了三种编码方式UTF-8、UTF-16、UTF-32,他们之间不是简单的内存扩展的关系
4. UTF-8变长编码方式,优点:英文环境下内存占用空间少,英文环境下计算效率高。缺点: 表示两个字节的字符码点时需要用到可能3个字节的信息保存因为他的编码方式会额外占用bit位(这里说一下为什么明明码点才2两位,通过编码方式编码后反而需要更多的内存空间,因为编码方式是一种码点与内存的转换规则,他需要解决的问题不仅是空间浪费问题，同时还要清晰的定义出当前字节在规则中充当的角色,以UTF-8举例,系统可以知道按照UTF-8的形式来解码,但是他无法确定你当前字节是直接按照规则解析为字符还是作为另一个字符的一部分出现,因此构造一个编码方式时需要考虑使用一定的方式来清晰的给到系统一个判别方式，这样就会造成一定的空间额外占用)。具体的UTF-8编码方式简述: 0000 0000到0111 1111(首位只能是0)的范围的字符使用码点直接表示，超过的首先第一个字节的首位一定是1，后续的按照第一个字节的2～8位表示整个字符占用的字节数，例如1111,第一位表示这个字节需要关联多个字节表示,后面的三位表示后续需要拼接3个字节,那么剩余的4位表示码点的前4位，后面每个字节均以10开头占位，剩下6位表示码点的后续内容,这样就保证了任意位置上的字符不会出现被系统错误判断的可能,因为0开头的字节一定是在0000 0000 ～ 0111 1111范围内的码点,1开头的字节要么是10开头作为其他字符的组成部分要么是n个1表示某个多字节的开头字节
5. UTF-16也是变长编码但是它的变长不是UTF-8的变长,他将Unicode码表分成了两部分(这里由于涉及到多字节后面使用16进制表示),0x0000~0xFFFF表示的65536(两个字节16位,<u>0 ～ 2^16 - 1</u>,减去1是因为2^16 =65,536 = 0x010000)码点组成的基本面，和剩下的辅助面，编码方式总结就是基本面的D800~DC00以外的字符都是直接跟码点一只，辅助面的都用四个字节来表示，前面两个字节表示高位代理，后两个字节表示低位代理,高位代理的值范围是基本面的D800～DBFF具体计算过程查看B站视频,低位代理是DC00~DFFF。因此系统可以根据UTF-16编码后的任意2个内存字节,如果整个的值坐落在Unicode字符集的代理区外,则直接就是码点，如果是代理区内根据范围就可以确定他是高位代理还是地位代理，并且一定可以知道的是这两个字节是某个字符的码点还是高位代理单元还是地位代理单元，这种可知性能够让安全性得到提高，并且在基本面的字符是固定两个字节的码点原值，中文字符计算的效率比UTF-8要高，而且任意部分的缺失影响较小。JAVA中的char在JDK8之前就是采用了UTF-16的方式进行虚拟机内存的转换，因为这样可以让char的内存固定为2个字节，当基本面的字符进来时一个char完全可以保存，当辅助面的字符进来时也可以清晰的保存一个代理单元不会导致解码失败或者需要调整内存大小的情况出现
6. 大小端，大小端表示的是解码后字节在内存存储的方式，分别表示了从左到右和从右到左保存的两种方式
7. BOM，任意文本文件如果没有指明BOM表示UTF-8编码，BOM表示了本文件采用的编码格式，当你选择了某个格式后会在文件的开端加上BOM信息表示当前文件的编码信息

